"""
FreeFans Telegram Bot - Main Bot File (Modularized)
A bot for accessing creator content with filtering capabilities
"""

import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes
from telegram.error import TimedOut, NetworkError, BadRequest, RetryAfter
from decouple import config
import asyncio

# Import modular components
from content_manager import ContentManager
from user_session import UserSession
from bot.command_handlers import start_command, help_command
from bot.search_handler import handle_creator_search
from bot.callback_handlers import handle_callback_query
from cache_manager import CacheManager
from background_scraper import BackgroundScraper
from content_scraper import SimpleCityScraper

# Enable logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Reduce httpx logging noise (only show warnings and errors)
logging.getLogger('httpx').setLevel(logging.WARNING)


class FreeFansBot:
    """Main bot class that coordinates all bot operations."""
    
    def __init__(self, cache_manager: CacheManager, background_scraper: BackgroundScraper):
        self.cache_manager = cache_manager
        self.background_scraper = background_scraper
        self.content_manager = ContentManager(cache_manager)
        self.user_sessions = {}

    
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Send a message when the command /start is issued."""
        await start_command(update, context, self)

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Send a message when the command /help is issued."""
        await help_command(update, context)
    
    async def cache_stats_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Show enhanced cache statistics with smart caching info."""
        try:
            stats = self.background_scraper.get_stats()
            cache_stats = stats['cache_stats']
            
            status_emoji = {
                'running': 'üîÑ',
                'waiting': '‚è≥',
                'stopped': '‚èπÔ∏è',
                'error': '‚ùå'
            }
            
            # Smart caching status
            initial_complete = getattr(self.background_scraper, '_initial_cache_complete', False)
            background_complete = getattr(self.background_scraper, '_background_cache_complete', False)
            
            smart_status = ""
            if initial_complete and background_complete:
                smart_status = "‚úÖ All phases complete"
            elif initial_complete:
                smart_status = "üéØ Phase 1 complete, Phase 2 in progress"
            else:
                smart_status = "üöÄ Phase 1 in progress"
            
            message = f"""
üìä **Enhanced Cache Statistics**

**Smart Caching Status:** {smart_status}
‚Ä¢ Phase 1 (Priority): {"‚úÖ Complete" if initial_complete else "üîÑ Running"}
‚Ä¢ Phase 2 (Background): {"‚úÖ Complete" if background_complete else "‚è≥ Pending" if initial_complete else "‚è∏Ô∏è Waiting"}

**SimpCity Content:**
‚Ä¢ Cached Creators: {cache_stats['total_creators']}
‚Ä¢ Content Items: {cache_stats['total_content_items']}
‚Ä¢ Preview Images: {cache_stats['total_preview_images']}
‚Ä¢ Video Links: {cache_stats['total_video_links']}

**OnlyFans/Coomer Data:**
‚Ä¢ Cached Users: {cache_stats['total_onlyfans_users']}
‚Ä¢ Cached Posts: {cache_stats['total_onlyfans_posts']}

**Database Info:**
‚Ä¢ Size: {cache_stats['database_size_mb']} MB

**Background Scraper:**
{status_emoji.get(stats['current_status'], '‚ùì')} Status: {stats['current_status']}
‚Ä¢ Total Processed: {stats['total_processed']}
‚Ä¢ Success Rate: {stats.get('success_rate', 0)*100:.1f}%
‚Ä¢ Pending Retries: {stats.get('pending_retries', 0)}

**Performance:**
‚Ä¢ Processing Rate: {stats['performance']['processing_rate']:.1f} creators/min
‚Ä¢ Avg Time/Creator: {stats['performance']['average_time_per_creator']:.1f}s
‚Ä¢ Active Workers: {stats['performance']['active_workers']}

**Last Refresh:** {stats.get('last_run', 'Never')[:19] if stats.get('last_run') else 'Never'}
**Next Refresh:** {stats.get('next_run', 'Not scheduled')[:19] if stats.get('next_run') else 'Not scheduled'}

üí° Smart caching prioritizes uncached creators first!
üîÑ Periodic refresh every {self.background_scraper.refresh_interval.total_seconds()/3600:.0f} hours
            """
            
            await update.message.reply_text(message, parse_mode='Markdown')
            
        except Exception as e:
            logger.error(f"Error showing cache stats: {e}")
            await update.message.reply_text("‚ùå Failed to retrieve cache statistics.")

    async def handle_creator_search(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle creator name input and search for content."""
        await handle_creator_search(update, context, self)

    async def handle_callback_query(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle callback queries from inline keyboards."""
        await handle_callback_query(update, context, self)
    
    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle errors caused by Updates."""
        logger.error(f"Exception while handling an update: {context.error}", exc_info=context.error)
        
        error_message = "‚ùå An unexpected error occurred. Please try again later."
        
        try:
            if isinstance(context.error, TimedOut):
                error_message = "‚è±Ô∏è Request timed out. Please check your connection and try again."
                logger.error("Telegram API timeout occurred")
            elif isinstance(context.error, NetworkError):
                error_message = "üåê Network error. Please check your internet connection and try again."
                logger.error(f"Network error: {context.error}")
            elif isinstance(context.error, RetryAfter):
                retry_after = context.error.retry_after
                error_message = f"‚è∏Ô∏è Too many requests. Please wait {retry_after} seconds before trying again."
                logger.error(f"Rate limited. Retry after {retry_after}s")
            elif isinstance(context.error, BadRequest):
                error_message = "‚ùå Invalid request. Please try a different action."
                logger.error(f"Bad request: {context.error}")
            elif isinstance(context.error, RuntimeError) and "no bot associated" in str(context.error):
                error_message = "‚ö†Ô∏è Internal error occurred. Please try your action again."
                logger.error(f"Bot association error: {context.error}")
            else:
                logger.error(f"Unhandled error type: {type(context.error).__name__}: {context.error}")
            
            # Try to notify the user
            if update and hasattr(update, 'effective_message') and update.effective_message:
                try:
                    await asyncio.sleep(1)
                    await update.effective_message.reply_text(error_message)
                except Exception as e:
                    logger.error(f"Failed to send error message to user: {e}")
            elif update and hasattr(update, 'callback_query') and update.callback_query:
                try:
                    await asyncio.sleep(1)
                    await update.callback_query.answer(error_message, show_alert=True)
                except Exception as e:
                    logger.error(f"Failed to send error answer to callback query: {e}")
                    
        except Exception as e:
            logger.error(f"Error in error handler: {e}")


def main():
    """Start the bot."""
    # Get token from environment variable
    try:
        TOKEN = config('TELEGRAM_BOT_TOKEN')
    except:
        print("‚ùå Error: TELEGRAM_BOT_TOKEN not found in .env file")
        print("Please add your Telegram bot token to the .env file:")
        print("TELEGRAM_BOT_TOKEN=your_bot_token_here")
        return
    
    # Initialize cache manager
    print("üíæ Initializing cache manager...")
    cache_manager = CacheManager()
    cache_stats = cache_manager.get_cache_stats()
    print(f"‚úÖ Cache ready: {cache_stats['total_creators']} creators, "
          f"{cache_stats['total_content_items']} items cached")
    
    # Initialize background scraper with enhanced multithreading and configurable settings
    print("üîÑ Initializing enhanced background scraper...")
    scraper = SimpleCityScraper()
    
    # Get configuration from environment variables
    refresh_interval = int(config('CACHE_REFRESH_INTERVAL_HOURS', default=12))
    max_workers = int(config('SCRAPER_MAX_WORKERS', default=6))
    batch_size = int(config('SCRAPER_BATCH_SIZE', default=4))
    concurrent_requests = int(config('SCRAPER_CONCURRENT_REQUESTS', default=3))
    
    background_scraper = BackgroundScraper(
        cache_manager=cache_manager,
        scraper=scraper,
        refresh_interval_hours=refresh_interval,
        max_pages_per_creator=None,     # Scrape ALL pages per creator (unlimited)
        batch_size=batch_size,
        max_workers=max_workers,
        concurrent_requests=concurrent_requests
    )
    
    print(f"‚öôÔ∏è  Configuration:")
    print(f"   ‚Ä¢ Refresh interval: {refresh_interval} hours")
    print(f"   ‚Ä¢ Max workers: {max_workers}")
    print(f"   ‚Ä¢ Batch size: {batch_size}")
    print(f"   ‚Ä¢ Concurrent requests: {concurrent_requests}")
    
    # Smart caching strategy: Priority phase (uncached creators first)
    print("\nüöÄ Starting SMART CACHING with priority system...")
    print("üì• PHASE 1: Caching uncached creators first (PRIORITY - blocks bot startup)")
    print("üì• PHASE 2: Refresh cached creators in background (after bot starts)")
    print("‚ö° Enhanced features:")
    print("   ‚Ä¢ Smart priority system (uncached first)")
    print("   ‚Ä¢ Multithreaded processing with configurable workers")
    print("   ‚Ä¢ Intelligent rate limiting with adaptive delays")
    print("   ‚Ä¢ Rotating headers to avoid bot detection")
    print("   ‚Ä¢ Exponential backoff retry logic")
    print("   ‚Ä¢ Real-time performance monitoring")
    print("‚è±Ô∏è  Estimated priority phase time: 5-15 minutes (only uncached creators)")
    print("‚è∏Ô∏è  Bot will START after priority phase completes.\n")
    
    import asyncio
    print("üéØ Starting PHASE 1: Priority caching (uncached creators only)...")
    asyncio.run(background_scraper.initialize_cache_from_csv(max_creators=None))  # None = unlimited
    print("‚úÖ PHASE 1 complete! Bot can now start.\n")
    
    # Start background scraper for periodic updates and background caching
    background_scraper.start()
    print("‚úÖ Enhanced background scraper started:")
    print(f"   ‚Ä¢ PHASE 2 will run in background (refresh cached creators)")
    print(f"   ‚Ä¢ Periodic full refresh every {refresh_interval} hours")
    print("   ‚Ä¢ Bot is now operational!\n")
    
    # Preload CSV cache for faster searches
    print("üìÇ Preloading CSV cache...")
    from scrapers.csv_handler import preload_csv_cache
    try:
        count = preload_csv_cache()
        print(f"‚úÖ Preloaded {count} models into CSV cache\n")
    except Exception as e:
        print(f"‚ö†Ô∏è Warning: Failed to preload CSV cache: {e}\n")
    
    # Create application with custom settings for better timeout handling
    print("ü§ñ Initializing Telegram bot...")
    application = (
        Application.builder()
        .token(TOKEN)
        .connect_timeout(30.0)
        .read_timeout(30.0)
        .write_timeout(30.0)
        .pool_timeout(30.0)
        .build()
    )
    
    # Initialize bot with cache and scraper
    bot = FreeFansBot(cache_manager, background_scraper)
    
    # Register handlers
    application.add_handler(CommandHandler("start", bot.start))
    application.add_handler(CommandHandler("help", bot.help_command))
    application.add_handler(CommandHandler("cache", bot.cache_stats_command))
    application.add_handler(CallbackQueryHandler(bot.handle_callback_query))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, bot.handle_creator_search))
    
    # Register error handler
    application.add_error_handler(bot.error_handler)
    
    # Run the bot
    print("‚úÖ All systems ready!")
    print("‚úÖ Error handlers registered")
    print("‚úÖ Timeout settings configured")
    print("‚úÖ Cache system enabled and populated")
    print("ÔøΩ Starting bot polling...\n")
    
    try:
        application.run_polling(allowed_updates=Update.ALL_TYPES)
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Stopping bot...")
    finally:
        # Stop background scraper on shutdown
        background_scraper.stop()
        print("‚úÖ Background scraper stopped")
        print("üëã Bot shutdown complete")


if __name__ == '__main__':
    main()

